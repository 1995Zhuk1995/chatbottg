{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сравнение оптимизаторов нейросетки для модели wordchar2vector с помощью ANOVA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Наша задача - определить лучший оптимизатор из [доступных на Keras](https://keras.io/optimizers/) и подтвердить выбор статистическими тестами. Модель - нейросетка, которая учится генерировать векторы для символьного представления слов (см. [описание](https://github.com/Koziev/chatbot/blob/master/PyModels/trainers/README.wordchar2vector.md)). Особенность нейросетевых моделей заключается в существенной стохастичности решения из-за нюансов начальной инициализации сетки, действий оптимизатора и случайного перемешивания данных в датасетах. Поэтому сравнение средней точности моделей для разных оптимизаторов мы дополним статистическими тестами. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import random\n",
    "import codecs\n",
    "import itertools\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.tokenizer import Tokenizer\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Списки файлов с историей обучения, сохраненных тренером модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# файлы лежат в ../tmp\n",
    "\n",
    "# оптимизатор nadam\n",
    "nadam_files = ['learning_curve__lstm(cnn)_vecsize=56_tunable_char_embeddings=0_chardims=87_batchsize=250_seed=123456.csv',\n",
    "               'learning_curve__lstm(cnn)_vecsize=56_tunable_char_embeddings=0_chardims=87_batchsize=250_seed=654321.csv',\n",
    "               'learning_curve__lstm(cnn)_vecsize=56_tunable_char_embeddings=0_chardims=87_batchsize=250_seed=654321_1.csv',\n",
    "               'learning_curve__lstm(cnn)_vecsize=56_tunable_char_embeddings=0_chardims=87_batchsize=250_seed=456789.csv',\n",
    "               'learning_curve__lstm(cnn)_vecsize=56_tunable_char_embeddings=0_chardims=87_batchsize=250_seed=5678901.csv']\n",
    "\n",
    "# оптимизатор rmsprop\n",
    "rmsprop_files = ['learning_curve__lstm(cnn)_vecsize=56_tunable_char_embeddings=0_chardims=87_batchsize=250_seed=10000234.csv',\n",
    "                 'learning_curve__lstm(cnn)_vecsize=56_tunable_char_embeddings=0_chardims=87_batchsize=250_seed=10013987.csv',\n",
    "                 'learning_curve__lstm(cnn)_vecsize=56_tunable_char_embeddings=0_chardims=87_batchsize=250_seed=10003987.csv',\n",
    "                 'learning_curve__lstm(cnn)_vecsize=56_tunable_char_embeddings=0_chardims=87_batchsize=250_seed=10001987.csv',\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_max_accuracy(dataframe_filename):\n",
    "    \"\"\"Получим максимальное значение достигнутой instance accuracy в каждом эксперименте\"\"\"\n",
    "    df = pd.read_csv(os.path.join(u'../tmp', dataframe_filename), header=None, encoding='utf-8', delimiter='\\t', index_col=None)\n",
    "    max_acc = np.amax(df[1].values)\n",
    "    return max_acc\n",
    "\n",
    "def get_samples(dataframe_filenames):\n",
    "    return [find_max_accuracy(fname) for fname in dataframe_filenames]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Получим выборки отдельно для каждого оптимизатора\n",
    "samples_nadam = get_samples(nadam_files)\n",
    "samples_rmsprop = get_samples(rmsprop_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92000000000000004, 0.91900000000000004, 0.91799999999999993, 0.93000000000000005, 0.94299999999999995]\n",
      "[0.83900000000000008, 0.873, 0.80400000000000005, 0.88700000000000001]\n"
     ]
    }
   ],
   "source": [
    "print(samples_nadam)\n",
    "print(samples_rmsprop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANOVA: односторонний F-тест для проверки нулевой гипотезы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Проверяем гипотезу: выборочные средние равны, а отличия вызваны случайными причинами (высокой стохастичностью процесса обучения)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one-way p=0.00322564771963\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats\n",
    "\n",
    "res = scipy.stats.f_oneway(samples_nadam, samples_rmsprop)\n",
    "print('one-way p={}'.format(res.pvalue))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### При доверительном интервале 0.05 получаемое значение p говорит о том, что риск ошибки при отказе от нулевой гипотезы достаточно мал"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
